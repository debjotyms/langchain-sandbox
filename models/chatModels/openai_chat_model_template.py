from langchain_openai import ChatOpenAI
from dotenv import load_dotenv

load_dotenv()

openai_chat_model = ChatOpenAI(model='gpt-4')
result = openai_chat_model.invoke("Who is Elon Musk?")

print(result)

# load_dotenv() → Used to load API key from the .env file.
# .invoke() → Takes a string as prompt and returns the result as a string.
# result → This would be a langchain_core.messages.AIMessage object. This object contains the content generated by the ChatOpenAI model.